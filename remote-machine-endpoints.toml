# Remote machine endpoints: machine_id -> OpenAI-compatible base URL.
#
# Channel of communication: Tailscale only. Each machine publishes its Tailscale IP
# (base_url = "http://<tailscale-ip>:1234/v1") via dotfiles tailscale-publish-endpoints
# at boot. No ngrok is used for this repo.
#
# Section name = output of dotfiles/scripts/machine-user-id.sh (uname|hostname|user|cpu|gpu).
# Same key as ~/.config/lmstudio-remote.toml. For lookup: run that script on the target
# machine to get its key, then use that key in credentials and in REMOTE_MACHINE_ID.
#
# Refs: dotfiles docs/tailscale-publish-endpoints-at-boot.md, docs/lmstudio-ngrok-remote.md


["Linux|agent|agent|11th Gen Intel(R) Core(TM) i7-11800H @ 2.30GHz|NVIDIA GeForce RTX 3050 Ti Laptop GPU (4096 MiB)"]
base_url = "http://100.89.202.61:1234/v1"
load_model = "qwen2.5-vl-3b-instruct"

["Linux|agent16|agent|13th Gen Intel(R) Core(TM) i9-13950HX|NVIDIA GeForce RTX 4090 Laptop GPU (16376 MiB)"]
base_url = "http://100.83.31.44:1234/v1"
load_model = "qwen2.5-7b-instruct"

loaded_model = "Qwen2.5 7B Instruct"
loaded_model_key = "qwen2.5-7b-instruct"
["Linux|agent-dell-cpu|agent|11th Gen Intel(R) Core(TM) i7-1185G7 @ 3.00GHz|02.0 VGA compatible controller: Intel Corporation TigerLake-LP GT2 [Iris Xe Graphics] (rev 01)"]
base_url = "http://100.70.159.64:1234/v1"
load_model = "text-embedding-embedding-gemma-300m"
